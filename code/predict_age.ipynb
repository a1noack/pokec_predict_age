{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "import copy\n",
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.chdir('../InferSent/')\n",
    "from models import InferSent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the profiles and edges information into two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamnoack/anaconda/envs/hack/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "columns = ['user_id', 'public', 'completion_percentage', 'gender', 'region', 'last_login', 'registration', 'age', 'body',\n",
    "    'I_am_working_in_field', 'spoken_languages', 'hobbies', 'I_most_enjoy_good_food', 'pets', 'body_type', 'my_eyesight',\n",
    "    'eye_color', 'hair_color', 'hair_type', 'completed_level_of_education', 'favourite_color', 'relation_to_smoking',\n",
    "    'relation_to_alcohol', 'sign_in_zodiac', 'on_pokec_i_am_looking_for', 'love_is_for_me', 'relation_to_casual_sex',\n",
    "    'my_partner_should_be', 'marital_status', 'children', 'relation_to_children', 'I_like_movies', 'I_like_watching_movie',\n",
    "    'I_like_music', 'I_mostly_like_listening_to_music', 'the_idea_of_good_evening', 'I_like_specialties_from_kitchen',\n",
    "    'fun', 'I_am_going_to_concerts', 'my_active_sports', 'my_passive_sports', 'profession', 'I_like_books', 'life_style',\n",
    "    'music', 'cars', 'politics', 'relationships', 'art_culture', 'hobbies_interests', 'science_technologies',\n",
    "    'computers_internet', 'education', 'sport', 'movies', 'travelling', 'health', 'companies_brands', 'more', 'huh']\n",
    "\n",
    "profiles = pd.read_csv('../data/pokec/soc-pokec-profiles.txt', sep='\\t', names=columns)\n",
    "edges = pd.read_csv('../data/pokec/soc-pokec-relationships.txt', sep='\\t', names=['source', 'destination'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unwanted columns and drop those rows that have NaN values for the columns we care about and create aggregate sentence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>agg_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>take co ma uputaju cestovanie, pocuvanie hudby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>akcne, horory, komedie, serialy, dokumentarne,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>horory, komedie, romanticke, serialy, rodinne ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id   age  gender                                           agg_sent\n",
       "0      16  23.0     1.0  take co ma uputaju cestovanie, pocuvanie hudby...\n",
       "1      32  21.0     1.0  akcne, horory, komedie, serialy, dokumentarne,...\n",
       "2      46  21.0     0.0  horory, komedie, romanticke, serialy, rodinne ..."
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vars = ['I_like_movies', 'hobbies', 'children', 'profession']\n",
    "numerical_vars = ['user_id', 'age','gender']\n",
    "\n",
    "profiles_ss = profiles[numerical_vars + sentence_vars]\n",
    "profiles_ss = profiles_ss.dropna()\n",
    "profiles_ss = profiles_ss[(profiles_ss.age > 5) & (profiles_ss.age < 75)].reset_index(drop=True)\n",
    "\n",
    "profiles_ss['agg_sent'] = profiles_ss['I_like_movies'] + ' ' + profiles_ss['hobbies'] + ' ' + profiles_ss['children'] + ' ' + profiles_ss['profession']\n",
    "profiles_ss = profiles_ss.drop(sentence_vars, axis=1)\n",
    "\n",
    "profiles_ss.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't shuffle, because the smaller profile_1.user_id - profile_2.user_id is, the more likely \n",
    "# it is that profile_1 and profile_2 are friends\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original number of samples: 174,483\n",
      "new number of samples: 33,876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>agg_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>7209</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neviem nemam na ne cas ale uz ked tak mam rad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>7226</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>michael jackson velmi rad pocuvam michaela jac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>7210</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>akcne, komedie, serialy pocuvanie hudby, tanco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id   age  gender                                           agg_sent\n",
       "1020    7209  23.0     1.0  neviem nemam na ne cas ale uz ked tak mam rad ...\n",
       "1021    7226  14.0     1.0  michael jackson velmi rad pocuvam michaela jac...\n",
       "1022    7210  18.0     0.0  akcne, komedie, serialy pocuvanie hudby, tanco..."
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fraction of data to use\n",
    "fraction = 1/5\n",
    "\n",
    "num_samples = len(profiles_ss.index)\n",
    "print(\"original number of samples: {:,}\".format(num_samples))\n",
    "\n",
    "# save profiles_ss to pickle file\n",
    "profiles_ss.to_pickle('../data/pokec_cleaned/profiles_ss.pkl')\n",
    "\n",
    "#shuffle rows of profiles_ss. essentially randomly sampling\n",
    "if shuffle:\n",
    "    profiles_ss = profiles_ss.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# retain only a fraction of the original data\n",
    "profiles_ss = profiles_ss[:int(num_samples*fraction)]\n",
    "\n",
    "profiles_ss = profiles_ss[1020:]\n",
    "\n",
    "num_samples = len(profiles_ss.index)\n",
    "print(\"new number of samples: {:,}\".format(num_samples))\n",
    "\n",
    "profiles_ss.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate the sentences in the agg_sent column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences per translator.translate call: 33\n"
     ]
    }
   ],
   "source": [
    "split_amt = 1000\n",
    "segment_len = int(num_samples/split_amt)\n",
    "\n",
    "# if true, save the new dataframe\n",
    "save = True\n",
    "\n",
    "print(\"number of sentences per translator.translate call: {:,}\".format(segment_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "exiting for loop\n"
     ]
    }
   ],
   "source": [
    "agg_sent = list(profiles_ss['agg_sent'])\n",
    "\n",
    "translations_text = []\n",
    "for i in range(split_amt):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        if i < split_amt - 1:\n",
    "            translations = translator.translate(agg_sent[i*segment_len:(i+1)*segment_len])\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            translations = translator.translate(agg_sent[i*segment_len:])\n",
    "        translations_text.extend([translation.text for translation in translations])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('exiting for loop')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_translations = len(translations_text)\n",
    "len_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamnoack/anaconda/envs/hack/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "profiles_truncated = profiles_ss[:len_translations]\n",
    "\n",
    "profiles_truncated['agg_sent_trans'] = translations_text\n",
    "\n",
    "if save:\n",
    "    profiles_truncated.to_pickle('../data/pokec_cleaned/profiles_truncated1020.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action, horror, comedy, sci-fi, family, box-office, but mainly cartoon: d sports, work with pc, pc games, web surfing, watching movies, discos, pool, cooking, cinema, party, sleeping, shopping, these are really many :-) yet none yet: d'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profs_1 = pd.read_pickle('../data/pokec_cleaned/profiles_truncated.pkl')\n",
    "profs_2 = pd.read_pickle('../data/pokec_cleaned/profiles_truncated510.pkl')\n",
    "profs_3 = pd.read_pickle('../data/pokec_cleaned/profiles_truncated1020.pkl')\n",
    "\n",
    "profs_all = pd.concat([profs_1, profs_2, profs_3])\n",
    "profs_all.loc[1544, 'agg_sent_trans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the InferSent sentence embedding model and the word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 2048\n",
    "\n",
    "model_version = 1\n",
    "MODEL_PATH = \"encoder/infersent%s.pickle\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': embedding_size,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Keep it on CPU or put it on GPU\n",
    "use_cuda = False\n",
    "model = model.cuda() if use_cuda else model\n",
    "\n",
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = 'dataset/GloVe/glove.840B.300d.txt' if model_version == 1 else 'dataset/fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)\n",
    "\n",
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the english sentences using the InferSent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sents = model.encode(list(profiles_ss.agg_sent_trans), bsize=128, tokenize=False, verbose=True)\n",
    "df_enc_sents = pd.DataFrame(enc_sents, columns=list(range(embedding_size*2)))\n",
    "profiles_ss = pd.concat([profiles_ss[numerical_vars], df_enc_sents], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the average aggregate sentence embedding of each profile's friends and combine these new features with the original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_and_merge(profs, edges):\n",
    "    profs_avgs = pd.DataFrame(columns=profs.columns)\n",
    "    for index in range(len(profs.index)):\n",
    "        friend_idxs = list(edges[edges.source == index].destination)\n",
    "        profs_avgs.loc[index] = list(profs.loc[friend_idxs].mean())\n",
    "    profs_aggregate = pd.concat([profs, profs_avgs], axis=1)\n",
    "    return profs_aggregate\n",
    "\n",
    "# profee = average_and_merge(profs, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "df2 = pd.DataFrame(columns=list(range(len(l))))\n",
    "\n",
    "df2.loc[0] = l\n",
    "\n",
    "edges_mini = pd.DataFrame({'source':[1,1,1,1,2,2,2,3,3,4,4,4,5,5,5,6,7,7], 'destination':[4,5,6,7,3,4,7,2,5,1,2,5,1,3,4,1,1,2]}, columns=['source', 'destination'])\n",
    "\n",
    "num_feats = 7\n",
    "profs_mini = pd.DataFrame(columns=list(range(num_feats)))\n",
    "for i in range(num_feats):\n",
    "    profs_mini.loc[i+1] = list(range(i*num_feats, (i+1)*num_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'1':[1,2,3],'2':[4,5,6],'3':[7,8,9]}, columns=['1', '2', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index.name = 'u_id'\n",
    "df1.index -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'source':[0,0,1,1,2,2], 'destination':[1,2,0,2,0,1]}, columns=['source', 'destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = average_and_merge(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3\n",
       "u_id         \n",
       "0     1  4  7\n",
       "1     2  5  8\n",
       "2     3  6  9"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  destination\n",
       "0       0            1\n",
       "1       0            2\n",
       "2       1            0\n",
       "3       1            2\n",
       "4       2            0\n",
       "5       2            1"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3    1    2    3\n",
       "u_id                        \n",
       "0     1  4  7  2.5  5.5  8.5\n",
       "1     2  5  8  2.0  5.0  8.0\n",
       "2     3  6  9  1.5  4.5  7.5"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hack]",
   "language": "python",
   "name": "conda-env-hack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
